version: "3"

tasks:
  python_deps:
    desc: setting up env with uv package manager for python and installing requirements. TODO still a bit of a mess with UV and taskfile
    cmds:
      - python3 -m pip install uv
      # - uv venv  # Create a virtual environment at .venv. # limitation cant create venv with make file due to limitation: ask runs as a subprocess of your current shell, so it can't change the environment of the shell that started it.
      # - source .venv/bin/activate
      # - uv pip install -r requirements.txt
      # - uv venv && source .venv/bin/activate && uv pip sync requirements.txt
      - uv venv && source .venv/bin/activate && uv pip install -r requirements.txt
      # - python -m pip install --progress-bar off -r requirements.txt
      # - pip install -r requirements.txt
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR} && dbt deps
      - cd transformation/demo_transformation_jaffle_shop && dbt deps
  python_deps_devcontainer:
    desc: Limitation with taskfile cant use vertial envs. So cant use UV
    cmds:
      # - pip install -r requirements.txt
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR} && dbt deps
      # workaround as cant get dynamic manifest.json to build
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR} && dbt parse

      - cd ${GITHUB_WORKSPACE}/transformation/demo_transformation_jaffle_shop && dbt deps
      - cd ${GITHUB_WORKSPACE}/transformation/demo_transformation_jaffle_shop && dbt parse

      - cd ${GITHUB_WORKSPACE}/transformation/pipeline_nsw_doe_requires_secrets && dbt deps
      - cd ${GITHUB_WORKSPACE}/transformation/pipeline_nsw_doe_requires_secrets && dbt parse

      - cd ${GITHUB_WORKSPACE}/transformation/demo_pipeline_scaling_tpch && dbt deps
      - cd ${GITHUB_WORKSPACE}/transformation/demo_pipeline_scaling_tpch && dbt parse


  node_deps:
    cmds:
      - npm install --prefix ${GITHUB_WORKSPACE}/reports

  git:
    cmds:
      - git config --global alias.lg "log --color --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit"
      - git config --global user.name "example user"
      - git config --global user.email username@example.com
      - pre-commit install
  znap:
    cmds:
      - export ZSH=~/.oh-my-zsh/
      - git clone --depth 1 https://github.com/marlonrichert/zsh-snap.git ~/.oh-my-zsh/custom/plugins/znap
      - echo "source ~/.oh-my-zsh/custom/plugins/znap/znap.zsh" >> ~/.zshrc
      - zsh ~/.zshrc
  zsh_plugins:
    desc: "note task doesnt execute in zsh so you need to prepend the below. Or you get the error executable file not found in $PATH see: https://github.com/go-task/task/discussions/1016"
    cmds:
      - zsh -i -c "znap source marlonrichert/zsh-autocomplete"

  setup:
    cmds:
      # - task temp_limitation # can remove this now?
      - task python_deps_devcontainer
      - task git
      - task znap # already exists in devcontainer
      - task zsh_plugins
      # - task orchestration_setup_devcontainer
      - task setup_sqltools
      # - task airbyte
      # - task octavia_setup

  setup_local:
    cmds:
      # - task temp_limitation # can remove this now?
      - task python_deps
      - task node_deps
      - task git
      - task znap
      - task zsh_plugins
      - task orchestration_setup
      # - task airbyte
      # - task octavia_setup

  # airbyte:
  #   desc: "install airbyte"
  #   cmds:
  #     - ./ingestion/run-ab-platform.sh
  # octavia:
  #   desc: "applies latest config to airbyte"
  #   cmds:
  #     - cd ./ingestion/my_octavia_project && octavia apply
  # octavia_setup:
  #   desc: "install airbyte cli octavia"
  #   cmds:
  #     - ./ingestion/octavia-cli-install.sh -Y
  #     - task octavia
  duck:
    cmds:
      - duckdb ${GITHUB_WORKSPACE}/$NSW_DOE_DATA_STACK_IN_A_BOX_DB_PATH_AND_DB
  duck_tpch:
    cmds:
      - duckdb ${GITHUB_WORKSPACE}/$TPCH_DB_PATH_AND_DB
  setup_sqltools:
    cmds:
      - cd ~/.local/share/vscode-sqltools && npm install duckdb-async@0.10.0 && exit 0
  evidence_setup:
    desc: dont need this now was just for inital setup just run node_deps
    cmds:
      - npm --prefix ${GITHUB_WORKSPACE}/reports install
      - npm --prefix ${GITHUB_WORKSPACE}/reports run sources

  evidence_prod_build:
    desc: static site generation for evidence
    cmds:
      - npm --prefix ${GITHUB_WORKSPACE}/reports run build
      - npm --prefix ${GITHUB_WORKSPACE}/reports run preview -- --port 4000
  evidence:
    desc: for local development we dont need to build the static site
    cmds:
      - npm --prefix ${GITHUB_WORKSPACE}/reports run dev # && simple-browser show http://localhost:3001/

  dag:
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DAGSTER_PROJECT_DIR} && DAGSTER_DBT_PARSE_PROJECT_ON_LOAD=1 && export DAGSTER_HOME=$GITHUB_WORKSPACE"/"$DAGSTER_HOME"/"$NSW_DOE_DATA_STACK_IN_A_BOX__ENV && dagster dev
  dag_requires_secrets:
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DAGSTER_PROJECT_DIR} && DAGSTER_DBT_PARSE_PROJECT_ON_LOAD=1 && export DAGSTER_HOME=$GITHUB_WORKSPACE"/"$DAGSTER_HOME"/"$NSW_DOE_DATA_STACK_IN_A_BOX__ENV && dagster dev
  orchestration_setup:
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DAGSTER_PROJECT_DIR} && uv pip install -e ".[dev]"
  orchestration_setup_devcontainer:
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DAGSTER_PROJECT_DIR} && pip install -e ".[dev]"
  dag_server:
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DAGSTER_PROJECT_DIR} && dagster dev -h 0.0.0.0 -p 3000

  docs:
    desc: documentation static site generator with mkdocs ðŸ’£ Warning doesnt work with taskfile ðŸš§ TODO
    cmds:
      - mkdocs serve

  mf_check:
    desc: compiles dbt code then runs the metric flow checker
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR} && dbt compile && mf validate-configs'
  mf:
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR} && dbt compile && mf query --saved-query metrics_by_year_saved_query --csv ./exports/sq-metrics-by-year-saved-query-non-dag.csv
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR} && dbt compile && mf query --saved-query metrics_by_year_school_saved_query --csv ./exports/sq-metrics-by-year-school-saved-query-non-dag.csv


  dbt_manifest_prod:
    desc: load the manifest from local if you run prod from local.
    cmds:
      - aws s3 cp ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR}/target/manifest.json s3://$S3_BUCKET_METADATA/prod/manifest/manifest.json
  dbt_prod_defer:
    desc: load the manifest from local if you run prod from local.
    cmds:
      - cd ${GITHUB_WORKSPACE}/${NSW_DOE_DATA_STACK_IN_A_BOX_DBT_PROJECT_DIR}
      - aws s3 cp s3://$S3_BUCKET_METADATA/prod/manifest/manifest.json ./target/last_manifest/manifest.json
      - dbt build --models state:modified+ --state ./target/last_manifest --profiles-dir .

  dbtdoc:
    cmds:
      - dbt docs generate
      - dbt docs serve
  dbtdoc_serv:
    cmds:
      - dbt docs serve
